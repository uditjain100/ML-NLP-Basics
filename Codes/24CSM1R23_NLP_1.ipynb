{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8bdb25",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:15:54.300608Z",
          "start_time": "2025-01-16T09:15:54.292755Z"
        },
        "id": "1a8bdb25"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5afac33",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:01:38.188658Z",
          "start_time": "2025-01-16T09:01:38.185441Z"
        },
        "id": "b5afac33"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "text = \"\"\"This is the first class of Natural Language Processing.\n",
        "I like the Natural Language Processing class.\n",
        "I am interested to learn Natural Language Models.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15efc020",
      "metadata": {
        "id": "15efc020"
      },
      "source": [
        "# Corpus, Documents, Word, Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773a8f8d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:01:52.430247Z",
          "start_time": "2025-01-16T09:01:52.427001Z"
        },
        "id": "773a8f8d",
        "outputId": "4408cd4e-7396-49c4-8f79-057cd8b434c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus: This is the first class of Natural Language Processing.\n",
            "I like the Natural Language Processing class.\n",
            "I am interested to learn Natural Language Models.\n"
          ]
        }
      ],
      "source": [
        "corpus = text\n",
        "print(\"Corpus:\", corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92195e40",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:02:00.099776Z",
          "start_time": "2025-01-16T09:02:00.093568Z"
        },
        "id": "92195e40",
        "outputId": "3efd4603-9c91-4d86-ae09-f0160f62c9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documents: ['This is the first class of Natural Language Processing.', 'I like the Natural Language Processing class.', 'I am interested to learn Natural Language Models.']\n"
          ]
        }
      ],
      "source": [
        "documents = sent_tokenize(text)\n",
        "print(\"Documents:\", documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ec7846",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:02:11.424665Z",
          "start_time": "2025-01-16T09:02:11.419938Z"
        },
        "id": "81ec7846",
        "outputId": "8c05de67-a9dc-40b7-a86c-f534f68c85b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words (tokenized for each document): [['This', 'is', 'the', 'first', 'class', 'of', 'Natural', 'Language', 'Processing', '.'], ['I', 'like', 'the', 'Natural', 'Language', 'Processing', 'class', '.'], ['I', 'am', 'interested', 'to', 'learn', 'Natural', 'Language', 'Models', '.']]\n"
          ]
        }
      ],
      "source": [
        "words = [word_tokenize(doc) for doc in documents]\n",
        "print(\"Words (tokenized for each document):\", words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaae5cbd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:02:23.205011Z",
          "start_time": "2025-01-16T09:02:23.201629Z"
        },
        "id": "aaae5cbd",
        "outputId": "96db2d2a-3119-4f0e-e97d-cc063e87cdc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: {'.', 'first', 'to', 'class', 'this', 'processing', 'i', 'is', 'the', 'interested', 'learn', 'models', 'of', 'language', 'like', 'natural', 'am'}\n"
          ]
        }
      ],
      "source": [
        "vocabulary = set(word.lower() for doc in words for word in doc)\n",
        "print(\"Vocabulary:\", vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b79dd2",
      "metadata": {
        "id": "64b79dd2"
      },
      "source": [
        "# Text Representation: One hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b0db78",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:11:33.468556Z",
          "start_time": "2025-01-16T09:11:33.463871Z"
        },
        "id": "86b0db78",
        "outputId": "800194ea-7ee8-4ec0-e5ff-28f00d7ed8b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens:  ['this', 'is', 'the', 'first', 'class', 'of', 'natural', 'language', 'processing', '.', 'i', 'like', 'the', 'natural', 'language', 'processing', 'class', '.', 'i', 'am', 'interested', 'to', 'learn', 'natural', 'language', 'models', '.']\n"
          ]
        }
      ],
      "source": [
        "tokens = word_tokenize(text.lower())\n",
        "print('Tokens: ', tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657d4686",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:11:43.105820Z",
          "start_time": "2025-01-16T09:11:43.102564Z"
        },
        "id": "657d4686",
        "outputId": "6c8191b9-4f74-44cb-89e3-8d0441bbf86a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['.', 'am', 'class', 'first', 'i', 'interested', 'is', 'language', 'learn', 'like', 'models', 'natural', 'of', 'processing', 'the', 'this', 'to']\n"
          ]
        }
      ],
      "source": [
        "vocabulary = sorted(set(tokens))\n",
        "print(\"Vocabulary:\", vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e84222",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:11:54.186016Z",
          "start_time": "2025-01-16T09:11:54.182526Z"
        },
        "id": "53e84222",
        "outputId": "5129c38e-97bc-41ef-cd44-59ca770bb718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word-to-Index Mapping: {'.': 0, 'am': 1, 'class': 2, 'first': 3, 'i': 4, 'interested': 5, 'is': 6, 'language': 7, 'learn': 8, 'like': 9, 'models': 10, 'natural': 11, 'of': 12, 'processing': 13, 'the': 14, 'this': 15, 'to': 16}\n"
          ]
        }
      ],
      "source": [
        "word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "print(\"Word-to-Index Mapping:\", word_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "921e5d16",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:14:40.338511Z",
          "start_time": "2025-01-16T09:14:40.325180Z"
        },
        "id": "921e5d16",
        "outputId": "6ecfa513-6241-4423-ff38-831114bb1de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Hot Encoded Vectors:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'.': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'am': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'class': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'first': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'i': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'interested': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'is': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'language': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'learn': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'like': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'models': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
              " 'natural': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
              " 'of': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
              " 'processing': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
              " 'the': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
              " 'this': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
              " 'to': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot_encoded = {}\n",
        "for word in vocabulary:\n",
        "    vector = np.zeros(len(vocabulary), dtype=int)\n",
        "    vector[word_to_index[word]] = 1\n",
        "    one_hot_encoded[word] = vector\n",
        "\n",
        "print(\"One-Hot Encoded Vectors:\")\n",
        "one_hot_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b13b9f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:16:07.918393Z",
          "start_time": "2025-01-16T09:16:07.913354Z"
        },
        "id": "30b13b9f"
      },
      "source": [
        "# Text Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2e9adb4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:20:47.997559Z",
          "start_time": "2025-01-16T09:20:47.994391Z"
        },
        "id": "e2e9adb4",
        "outputId": "8ee68210-ddde-41bb-d918-c43af7324ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Tokenization: ['This is the first class of Natural Language Processing.', 'I like the Natural Language Processing class.', 'I am interested to learn Natural Language Models.']\n"
          ]
        }
      ],
      "source": [
        "sentences = sent_tokenize(text)\n",
        "print(\"Sentence Tokenization:\", sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee984ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:38:15.141554Z",
          "start_time": "2025-01-16T09:38:15.136057Z"
        },
        "id": "cee984ad",
        "outputId": "71005f99-45dc-4a8a-a821-8ad29beb1001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Tokenization:\n",
            "Sentence: This is the first class of Natural Language Processing.\n",
            "Words: ['This', 'is', 'the', 'first', 'class', 'of', 'Natural', 'Language', 'Processing', '.']\n",
            "Sentence: I like the Natural Language Processing class.\n",
            "Words: ['I', 'like', 'the', 'Natural', 'Language', 'Processing', 'class', '.']\n",
            "Sentence: I am interested to learn Natural Language Models.\n",
            "Words: ['I', 'am', 'interested', 'to', 'learn', 'Natural', 'Language', 'Models', '.']\n"
          ]
        }
      ],
      "source": [
        "print(\"Word Tokenization:\")\n",
        "for sentence in sentences:\n",
        "    words = word_tokenize(sentence)\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Words:\", words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a4d4e0a",
      "metadata": {
        "id": "1a4d4e0a"
      },
      "source": [
        "# Stemming and Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d2e9fdd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:22:24.180511Z",
          "start_time": "2025-01-16T09:22:24.175171Z"
        },
        "id": "7d2e9fdd"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61dfd7dc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:24:45.590688Z",
          "start_time": "2025-01-16T09:24:45.586922Z"
        },
        "id": "61dfd7dc",
        "outputId": "25a7d13f-0426-481e-90b6-3772b04a45c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Words: {'Natural', 'first', 'Processing', 'class', '.', 'to', 'am', 'is', 'the', 'Language', 'interested', 'learn', 'of', 'Models', 'like', 'This', 'I'}\n"
          ]
        }
      ],
      "source": [
        "words = set(word_tokenize(text))\n",
        "print(\"Original Words:\", words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8ed061",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:24:50.383775Z",
          "start_time": "2025-01-16T09:24:50.379374Z"
        },
        "id": "4f8ed061",
        "outputId": "f2db761b-97d4-4e68-dc21-c16516ceb90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemmed Words: ['natur', 'first', 'process', 'class', '.', 'to', 'am', 'is', 'the', 'languag', 'interest', 'learn', 'of', 'model', 'like', 'thi', 'i']\n"
          ]
        }
      ],
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "print(\"Stemmed Words:\", stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b105ccd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:24:52.189476Z",
          "start_time": "2025-01-16T09:24:52.185378Z"
        },
        "id": "5b105ccd",
        "outputId": "1a7410cd-8cd3-4c75-f3a6-b3df0d158113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmatized Words:\n",
            "['natural', 'first', 'processing', 'class', '.', 'to', 'am', 'is', 'the', 'language', 'interested', 'learn', 'of', 'model', 'like', 'this', 'i']\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
        "\n",
        "print(\"Lemmatized Words:\")\n",
        "print(lemmatized_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d1b77c",
      "metadata": {
        "id": "b3d1b77c"
      },
      "source": [
        "# Edit Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531cabfa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:33:47.133100Z",
          "start_time": "2025-01-16T09:33:47.130337Z"
        },
        "id": "531cabfa"
      },
      "outputs": [],
      "source": [
        "from nltk.metrics import edit_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea62245",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:33:47.499086Z",
          "start_time": "2025-01-16T09:33:47.495981Z"
        },
        "id": "8ea62245",
        "outputId": "19acd159-892b-4036-c092-c9df49dc5418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Documents: ['This is the first class of Natural Language Processing.', 'I like the Natural Language Processing class.', 'I am interested to learn Natural Language Models.']\n"
          ]
        }
      ],
      "source": [
        "documents = sent_tokenize(text)\n",
        "print(\"Documents:\", documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36870b6a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:33:48.153877Z",
          "start_time": "2025-01-16T09:33:48.145087Z"
        },
        "id": "36870b6a",
        "outputId": "a2531f90-9503-4f5e-caf9-d0bb971a5dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edit Distance Between Sentences:\n",
            "Edit distance between:\n",
            "  'This is the first class of Natural Language Processing.'\n",
            "  'I like the Natural Language Processing class.'\n",
            "  -> 28\n",
            "\n",
            "Edit distance between:\n",
            "  'This is the first class of Natural Language Processing.'\n",
            "  'I am interested to learn Natural Language Models.'\n",
            "  -> 28\n",
            "\n",
            "Edit distance between:\n",
            "  'I like the Natural Language Processing class.'\n",
            "  'I am interested to learn Natural Language Models.'\n",
            "  -> 29\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Edit Distance Between Sentences:\")\n",
        "for i in range(len(documents)):\n",
        "    for j in range(i + 1, len(documents)):\n",
        "        dist = edit_distance(documents[i], documents[j])\n",
        "        print(f\"Edit distance between:\\n  '{documents[i]}'\\n  '{documents[j]}'\\n  -> {dist}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f44744aa",
      "metadata": {
        "id": "f44744aa"
      },
      "source": [
        "# N-gram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307fa0d0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:41:04.739984Z",
          "start_time": "2025-01-16T09:41:04.728998Z"
        },
        "id": "307fa0d0"
      },
      "outputs": [],
      "source": [
        "from nltk import ngrams, word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29eb32da",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:41:05.193384Z",
          "start_time": "2025-01-16T09:41:05.188017Z"
        },
        "id": "29eb32da",
        "outputId": "c2f3f0da-e8a5-4643-db12-8fbfb313c79c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'I',\n",
              " 'Language',\n",
              " 'Models',\n",
              " 'Natural',\n",
              " 'Processing',\n",
              " 'This',\n",
              " 'am',\n",
              " 'class',\n",
              " 'first',\n",
              " 'interested',\n",
              " 'is',\n",
              " 'learn',\n",
              " 'like',\n",
              " 'of',\n",
              " 'the',\n",
              " 'to'}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = set(word_tokenize(text))\n",
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8378e06f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:41:06.228617Z",
          "start_time": "2025-01-16T09:41:06.225783Z"
        },
        "id": "8378e06f"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(tokens, n):\n",
        "    return list(ngrams(tokens, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d408360d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:41:38.482273Z",
          "start_time": "2025-01-16T09:41:38.478636Z"
        },
        "id": "d408360d",
        "outputId": "404581f1-fb2a-4fde-bdf9-f098f753ee26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigrams: [('Natural',), ('first',), ('Processing',), ('class',), ('.',), ('to',), ('am',), ('is',), ('the',), ('Language',), ('interested',), ('learn',), ('of',), ('Models',), ('like',), ('This',), ('I',)]\n"
          ]
        }
      ],
      "source": [
        "unigrams = generate_ngrams(words, 1)\n",
        "print(\"Unigrams:\", unigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec40fcf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:41:08.908080Z",
          "start_time": "2025-01-16T09:41:08.904879Z"
        },
        "id": "6ec40fcf",
        "outputId": "ac39961d-3da2-4be1-eb95-bd774ef964f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigrams: [('Natural', 'first'), ('first', 'Processing'), ('Processing', 'class'), ('class', '.'), ('.', 'to'), ('to', 'am'), ('am', 'is'), ('is', 'the'), ('the', 'Language'), ('Language', 'interested'), ('interested', 'learn'), ('learn', 'of'), ('of', 'Models'), ('Models', 'like'), ('like', 'This'), ('This', 'I')]\n"
          ]
        }
      ],
      "source": [
        "bigrams = generate_ngrams(words, 2)\n",
        "print(\"Bigrams:\", bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8bef604",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-01-16T09:41:10.307474Z",
          "start_time": "2025-01-16T09:41:10.304177Z"
        },
        "id": "c8bef604",
        "outputId": "b7c03013-289e-4186-ac67-941360d8e2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trigrams: [('Natural', 'first', 'Processing'), ('first', 'Processing', 'class'), ('Processing', 'class', '.'), ('class', '.', 'to'), ('.', 'to', 'am'), ('to', 'am', 'is'), ('am', 'is', 'the'), ('is', 'the', 'Language'), ('the', 'Language', 'interested'), ('Language', 'interested', 'learn'), ('interested', 'learn', 'of'), ('learn', 'of', 'Models'), ('of', 'Models', 'like'), ('Models', 'like', 'This'), ('like', 'This', 'I')]\n"
          ]
        }
      ],
      "source": [
        "trigrams = generate_ngrams(words, 3)\n",
        "print(\"Trigrams:\", trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c56bd28",
      "metadata": {
        "id": "8c56bd28"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}