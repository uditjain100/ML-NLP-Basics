{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4QO03PHbKQH5Lyr1TRLvu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIQEij_U8jdv","executionInfo":{"status":"ok","timestamp":1728842861269,"user_tz":420,"elapsed":3359,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}},"outputId":"5fc044b6-0459-4455-9031-0b14809e5d6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.9)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers torch torch-geometric networkx scikit-learn pandas numpy"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel\n","import torch\n","\n","# Load pretrained BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Function to encode text using BERT\n","def encode_text(text):\n","    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","    outputs = bert_model(**inputs)\n","    return outputs.last_hidden_state.mean(dim=1)  # Return sentence embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JuixOw3e8kxH","executionInfo":{"status":"ok","timestamp":1728842861762,"user_tz":420,"elapsed":506,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}},"outputId":"d10b6508-51ad-4687-8406-54d18b1634fb"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import torch_geometric\n","from torch_geometric.nn import SAGEConv\n","import torch.nn.functional as F\n","\n","class PropagationEncoder(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, num_layers=2):\n","        super(PropagationEncoder, self).__init__()\n","        self.convs = torch.nn.ModuleList()\n","        self.convs.append(SAGEConv(in_channels, hidden_channels))\n","        for _ in range(num_layers - 1):\n","            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n","\n","    def forward(self, x, edge_index):\n","        for conv in self.convs:\n","            x = conv(x, edge_index)\n","            x = F.relu(x)\n","        return x.mean(dim=0)  # Graph-level representation"],"metadata":{"id":"jTgAiYdw8yCZ","executionInfo":{"status":"ok","timestamp":1728842861762,"user_tz":420,"elapsed":10,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import networkx as nx\n","from torch_geometric.utils import from_networkx\n","\n","# Create a sample graph\n","G = nx.Graph()\n","G.add_edges_from([(0, 1), (1, 2), (1, 3), (3, 4)])  # Simulate a propagation network\n","\n","# Add node features (e.g., follower count, retweet count)\n","for i in G.nodes:\n","    G.nodes[i]['feature'] = [1.0 * i]  # Example feature: the node index\n","\n","# Convert to torch_geometric Data object\n","data = from_networkx(G)\n","x = torch.tensor([G.nodes[i]['feature'] for i in G.nodes], dtype=torch.float)"],"metadata":{"id":"uDvWcQX38-H1","executionInfo":{"status":"ok","timestamp":1728842861762,"user_tz":420,"elapsed":8,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class MEFaND(torch.nn.Module):\n","    def __init__(self, text_hidden_size, graph_hidden_size):\n","        super(MEFaND, self).__init__()\n","        self.text_encoder = BertModel.from_pretrained('bert-base-uncased')\n","        self.graph_encoder = PropagationEncoder(in_channels=1, hidden_channels=graph_hidden_size)\n","        self.fc = torch.nn.Linear(text_hidden_size + graph_hidden_size, 1)\n","\n","    def forward(self, text, graph_x, edge_index):\n","        # Textual representation\n","        text_inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","        text_outputs = self.text_encoder(**text_inputs)\n","        text_embedding = text_outputs.last_hidden_state.mean(dim=1)\n","\n","        # Graph propagation representation\n","        graph_embedding = self.graph_encoder(graph_x, edge_index)\n","\n","        # Concatenate both embeddings\n","        combined = torch.cat([text_embedding, graph_embedding.unsqueeze(0)], dim=1)\n","\n","        # Return logits (no squeeze here)\n","        output = self.fc(combined)\n","        return output  # No need to squeeze, return output as is (shape [1, 1])\n"],"metadata":{"id":"1aSqmkxu9ASP","executionInfo":{"status":"ok","timestamp":1728842861763,"user_tz":420,"elapsed":8,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","# Create the MEFaND model\n","model = MEFaND(text_hidden_size=768, graph_hidden_size=128)\n","\n","# Loss and optimizer\n","criterion = torch.nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","\n","# Sample data (for demonstration purposes)\n","sample_text = \"India vs Bangladesh Highlights, 3rd T20I: India Rout Bangladesh By 133 Runs, Complete 2-1 Clean Sweep\"\n","sample_graph_x = x  # Node features from earlier\n","sample_edge_index = data.edge_index  # Edge index from earlier\n","sample_label = torch.tensor([1], dtype=torch.float).unsqueeze(0)  # Shape [1, 1]\n","\n","# Training loop\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    output = model(sample_text, sample_graph_x, sample_edge_index)  # Model output shape will be [1, 1]\n","    loss = criterion(output, sample_label)  # Both output and sample_label should be [1, 1]\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 10 == 0:\n","        print(f'Epoch {epoch}, Loss: {loss.item()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2u2SdJU79F6W","executionInfo":{"status":"ok","timestamp":1728843166169,"user_tz":420,"elapsed":128835,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}},"outputId":"a363f2bb-21b4-44ab-a4c7-8c073b957937"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.5282337069511414\n","Epoch 10, Loss: 0.03861550614237785\n","Epoch 20, Loss: 0.008564172312617302\n","Epoch 30, Loss: 0.0038216114044189453\n","Epoch 40, Loss: 0.0023992876522243023\n","Epoch 50, Loss: 0.0017736910376697779\n","Epoch 60, Loss: 0.0014257751172408462\n","Epoch 70, Loss: 0.0012036559637635946\n","Epoch 80, Loss: 0.0010418938472867012\n","Epoch 90, Loss: 0.0009170982521027327\n"]}]},{"cell_type":"code","source":["# Test on a new sample\n","test_text = \"India vs Bangladesh Highlights, 3rd T20I: India Rout Bangladesh By 133 Runs, Complete 3-0 Clean Sweep\"\n","test_graph_x = x\n","test_edge_index = data.edge_index\n","with torch.no_grad():\n","    test_output = model(test_text, test_graph_x, test_edge_index)\n","    print(f\"Prediction: {test_output.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEUOoQeE9I_X","executionInfo":{"status":"ok","timestamp":1728843206837,"user_tz":420,"elapsed":425,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}},"outputId":"c4d9b3db-6520-4196-f197-d2cd9ed7a077"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: 7.1115593910217285\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Assuming model output is the logit\n","logit_output = model(test_text, sample_graph_x, sample_edge_index)\n","\n","# Apply sigmoid to convert logit to probability\n","probability = torch.sigmoid(logit_output)\n","\n","# Convert probability to a binary prediction (1: fake, 0: real)\n","prediction = (probability > 0.5).float()  # Threshold at 0.5\n","\n","print(f\"Probability: {probability.item()}, Prediction: {prediction.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDxfmO0ZBBQ6","executionInfo":{"status":"ok","timestamp":1728843222257,"user_tz":420,"elapsed":777,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}},"outputId":"b7c5c58e-a9ef-49c4-c92b-613bbb65a3a4"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Probability: 0.9991850256919861, Prediction: 1.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OjmZ0EJ0DY4V","executionInfo":{"status":"ok","timestamp":1728843002181,"user_tz":420,"elapsed":5,"user":{"displayName":"Udit Jain","userId":"09056547328980284966"}}},"execution_count":37,"outputs":[]}]}